{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NB-SVM with SMOTE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markerenberg/Toxic-Comment-Classification/blob/master/NB_SVM_with_SMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6AvEhk7_upV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if GPU is enabled\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHXV-Uu90Ldo",
        "colab_type": "code",
        "outputId": "963c5d61-c8f1-4a54-e2e9-7ec89c08fc1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "##\n",
        "## =======================================================\n",
        "## Mark Erenberg \n",
        "## Toxic Comment Classification Challenge\n",
        "## =======================================================\n",
        "##\n",
        "\n",
        "# Objective: Create a model which predicts a probability of each type of toxicity for each comment.\n",
        "\n",
        "# import dependencies and files\n",
        "\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "from scipy.sparse import hstack\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import tempfile\n",
        "import warnings\n",
        "import ast\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "import gensim\n",
        "import gensim.models.keyedvectors as word2vec\n",
        "from gensim.models.fasttext import FastText\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "spacy_nlp = en_core_web_sm.load()\n",
        "spacy_nlp = spacy.load('en_core_web_sm')\n",
        "from spacy.lemmatizer import Lemmatizer\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "from sklearn import utils\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, average_precision_score\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Bidirectional, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model, Sequential\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "################### Data Loading ###################\n",
        "#os.chdir('C:\\\\Users\\\\marke\\\\Downloads\\\\Toxic Classification')\n",
        "train = pd.read_csv('train.csv').fillna('')\n",
        "test = pd.read_csv('test.csv').fillna('')\n",
        "\n",
        "train_text = train[['id','comment_text']].drop_duplicates()\n",
        "df = pd.concat([train_text,test],axis=0,ignore_index=True)\n",
        "\n",
        "################### Data Cleaning ####################\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "cv = CountVectorizer(min_df=0., max_df=1.)\n",
        "\n",
        "# Simple way to get the number of occurence of a regex\n",
        "def count_regexp_occ(regexp=\"\", text=None):\n",
        "    return len(re.findall(regexp, text))\n",
        "\n",
        "# Determine if file words exist:\n",
        "#print(len(df[df['comment_text'].str.contains('jpg')]))\n",
        "#print(len(df[df['comment_text'].str.contains('jpeg')]))\n",
        "#print(len(df[df['comment_text'].str.contains('http')]))\n",
        "#print(len(df[df['comment_text'].str.contains('pdf')]))\n",
        "#print(len(df[df['comment_text'].str.contains('html')]))\n",
        "\n",
        "# Remove non-alphabetic characters and split tokens by spaces/newlines\n",
        "def clean_document(doc):\n",
        "    # 1) Convert string to lower\n",
        "    #doc = bytes(doc.lower(), encoding=\"utf-8\")\n",
        "    doc = doc.lower()\n",
        "    # 2) Replace contracion patterns\n",
        "    cont_patterns = [\n",
        "    (r'(W|w)on\\'t', r'will not'),\n",
        "    (r'(C|c)an\\'t', r'can not'),\n",
        "    (r'(I|i)\\'m', r'i am'),\n",
        "    (r'(A|a)in\\'t', r'is not'),\n",
        "    (r'(\\w+)\\'ll', r'\\g<1> will'),\n",
        "    (r'(\\w+)n\\'t', r'\\g<1> not'),\n",
        "    (r'(\\w+)\\'ve', r'\\g<1> have'),\n",
        "    (r'(\\w+)\\'s', r'\\g<1> is'),\n",
        "    (r'(\\w+)\\'re', r'\\g<1> are'),\n",
        "    (r'(\\w+)\\'d', r'\\g<1> would'),\n",
        "    ]\n",
        "    patterns = [(re.compile(regex), repl) for (regex, repl) in cont_patterns]\n",
        "    for (pattern, repl) in patterns:\n",
        "        doc = re.sub(pattern, repl, doc)\n",
        "    # 3) Remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]+', '', doc)\n",
        "    #doc = doc.encode('utf-8')\n",
        "    #doc = str(doc,'utf-8').strip()\n",
        "    doc = doc.strip()\n",
        "    # tokenize document\n",
        "    tokens = wpt.tokenize(doc)\n",
        "    # filter stopwords out of document\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    # re-create document from filtered tokens\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    #doc = ' '.join(tokens)\n",
        "    return doc\n",
        "\n",
        "# Lemmaitze comments:\n",
        "def lemmatize_comment(comment):\n",
        "        doc = spacy_nlp(comment)\n",
        "        return [token.lemma_ for token in doc if token.lemma_ != '-PRON-' ]         \n",
        "\n",
        "\n",
        "## Clean and lemmatize comments\n",
        "#df['clean_comments'] = [clean_document(x) for x in df['comment_text']]\n",
        "#df['clean_comments_list'] = df['clean_comments'].apply(lambda x: x.split())\n",
        "#df['clean_lemmed'] = [lemmatize_comment(x) for x in df['clean_comments']]\n",
        "#df['clean_lemmed_str'] = df['clean_lemmed'].apply(lambda x: \" \".join(x))\n",
        "#train['clean_comments'] = [clean_document(x) for x in train['comment_text']]\n",
        "#train['clean_comments_list'] = train['clean_comments'].apply(lambda x: x.split())\n",
        "#train['clean_lemmed'] = [lemmatize_comment(x) for x in train['clean_comments']]\n",
        "#train['clean_lemmed_str'] = train['clean_lemmed'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "## Write to csv for download\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#train['clean_comments'].to_csv('train_clean_comments.csv',sep=',',index=False)\n",
        "#train['clean_lemmed'].to_csv('train_clean_lemmed.csv',sep=',',index=False)\n",
        "\n",
        "## Read from csv\n",
        "train_clean_comments = pd.read_csv('train_clean_comments.csv',header=None)\n",
        "train_clean_lemmed = pd.read_csv('train_clean_lemmed.csv',header=None)\n",
        "\n",
        "## Transform cleaned/lemmed strings\n",
        "train['clean_comments'] = train_clean_comments[0].apply(lambda x: str(x))\n",
        "train['clean_comments_list'] = train['clean_comments'].apply(lambda x: x.split())\n",
        "train['clean_lemmed'] = train_clean_lemmed[0].apply(lambda x: ast.literal_eval(x))\n",
        "train['clean_lemmed_str'] = train['clean_lemmed'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HsGQpdB9hFMJ",
        "outputId": "c0812a3e-e5c3-4c2c-8ffa-9b8a6b7f59c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "################### Compare with baseline TF-IDF features ###################\n",
        "\n",
        "# TF-IDF Vectorizer\n",
        "train_text = train['clean_lemmed_str']\n",
        "\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    min_df = 3,\n",
        "    max_df = 0.9,\n",
        "    sublinear_tf=True,\n",
        "    smooth_idf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=20000)\n",
        "word_vectorizer.fit(train_text)\n",
        "train_word_features = word_vectorizer.transform(train_text)\n",
        "\n",
        "char_vectorizer = TfidfVectorizer(\n",
        "    min_df = 3,\n",
        "    max_df = 0.9,\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='char',\n",
        "    stop_words='english',\n",
        "    ngram_range=(2, 6),\n",
        "    max_features=20000)\n",
        "char_vectorizer.fit(train_text)\n",
        "train_char_features = char_vectorizer.transform(train_text)\n",
        "\n",
        "train_tfidf_features = hstack([train_char_features, train_word_features]).tocsr()\n",
        "#train_tfidf_features = train_word_features.tocsr()\n",
        "\n",
        "# Create features about type of text and category of text\n",
        "def add_features(df):\n",
        "    # Get length in words and characters\n",
        "    df[\"word_count\"] = df[\"comment_text\"].apply(lambda x: len(x.split()))\n",
        "    df[\"word_len_avg\"] = df[\"comment_text\"].apply(lambda x: np.mean([len(x) for x in x.split()]))\n",
        "    df[\"word_len_std\"] = df[\"comment_text\"].apply(lambda x: np.std([len(x) for x in x.split()]))\n",
        "    df[\"char_count\"] = df[\"comment_text\"].apply(lambda x: len(x))\n",
        "    # Create count variables to see if any are useful\n",
        "    df[\"upper_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[A-Z]\", x)) /df['char_count']*100\n",
        "    df[\"number_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[0-9]\", x)) / df[\"char_count\"] *100\n",
        "    df[\"excl_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"!\", x)) / df[\"char_count\"] *100\n",
        "    df[\"quest_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\?\", x)) / df[\"char_count\"] *100\n",
        "    df[\"equals_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"=\", x)) / df[\"char_count\"] *100\n",
        "    df[\"punct_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[.!\\?=+#*|~-]\", x)) / df[\"char_count\"] *100\n",
        "    df[\"you_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\W[Yy]ou\\W\", x)) / df[\"word_count\"] *100\n",
        "    df[\"nb_fuck\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[Ff][uU][cC][Kk]\", x))\n",
        "    df[\"nb_suck\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[Ss]\\S{2}[Kk]\", x))\n",
        "    df[\"nb_dick\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[dD]ick\", x))\n",
        "    df[\"nb_penis\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[pP][eE][nN][iI][sS]\", x))\n",
        "    df[\"nb_pussy\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[pP][uU][sS][sS][yY]\", x))\n",
        "    df[\"nb_cock\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[cC]ock\", x))\n",
        "    df[\"8==D\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"8=+D\", x))\n",
        "    df[\"nb_gay\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[gG][aA][yY]\", x))\n",
        "    df[\"nb_bitch\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[bB][iI][tT][cC][hH]\", x))\n",
        "    df[\"nb_cunt\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[cC][uU][nN][tT]\", x))\n",
        "    df[\"nb_shut_up\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[sS][hH][uU][tT]\\s[uU][pP]\", x))\n",
        "    df[\"nb_mother\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\Wmother\\W\", x))\n",
        "    df[\"nb_ng\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\Wnigger\\W\", x))\n",
        "    df[\"nb_ng_2\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\Wnigga\\W\", x))\n",
        "\n",
        "def pos_tagging(df):\n",
        "    df[\"comment_raw\"] = df[\"comment_text\"].apply(lambda x: re.sub(r'[\\n\\r\\t\\r\\n]',r' ',x,re.I|re.U))\n",
        "    df[\"POS\"] = df[\"comment_raw\"].apply(lambda x: [token.pos_ for token in spacy_nlp(x)])\n",
        "    \n",
        "def pos_features(df):\n",
        "    # Get number of proper nouns\n",
        "    df[\"PROPN\"] = df[\"POS\"].apply(lambda x: len([pos for pos in x if pos == 'PROPN']))\n",
        "    df[\"ADJ\"] = df[\"POS\"].apply(lambda x: len([pos for pos in x if pos == 'ADJ']))\n",
        "    df[\"INTJ\"] = df[\"POS\"].apply(lambda x: len([pos for pos in x if pos == 'INTJ']))\n",
        "    df[\"SYM\"] = df[\"POS\"].apply(lambda x: len([pos for pos in x if pos == 'SYM']))\n",
        "\n",
        "    \n",
        "#add_features(train)\n",
        "#pos_tagging(df)\n",
        "#pos_features(df)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiYfLT5uX6RG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy import sparse\n",
        "class NbSvmClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, C=1.0, tol=1e-4, dual=False, n_jobs=1, multi_class='auto'):\n",
        "        self.C = C\n",
        "        self.tol=tol\n",
        "        self.dual = dual\n",
        "        self.n_jobs = n_jobs\n",
        "        self.multi_class = multi_class\n",
        "\n",
        "    def predict(self, x):\n",
        "        # Verify that model has been fit\n",
        "        check_is_fitted(self, ['_r', '_clf'])\n",
        "        return self._clf.predict(x.multiply(self._r))\n",
        "\n",
        "    def predict_proba(self, x):\n",
        "        # Verify that model has been fit\n",
        "        check_is_fitted(self, ['_r', '_clf'])\n",
        "        return self._clf.predict_proba(x.multiply(self._r))\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        # Check that X and y have correct shape\n",
        "        #y = y.values\n",
        "        x, y = check_X_y(x, y, accept_sparse=True)\n",
        "\n",
        "        def pr(x, y_i, y):\n",
        "            p = x[y==y_i].sum(0)\n",
        "            return (p+1) / ((y==y_i).sum()+1)\n",
        "\n",
        "        self._r = sparse.csr_matrix(np.log(pr(x,1,y) / pr(x,0,y)))\n",
        "        x_nb = x.multiply(self._r)\n",
        "        self._clf = LogisticRegression(C=self.C, tol=self.tol, dual=self.dual, n_jobs=self.n_jobs).fit(x_nb, y)\n",
        "        return self"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfTxVylQrWHG",
        "colab_type": "code",
        "outputId": "c657c7fb-5583-4990-b8ec-3bbb948407ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "## See what class imbalance is for response classes\n",
        "for clss in class_names:\n",
        "    true = [x for x in train[clss] if x == 1]\n",
        "    print(clss + \": \" + str(round(len(true)/len(train[clss])*100,2))+ \"%\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic: 9.58%\n",
            "severe_toxic: 1.0%\n",
            "obscene: 5.29%\n",
            "threat: 0.3%\n",
            "insult: 4.94%\n",
            "identity_hate: 0.88%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3tIKbXxaRgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5fb772ad-4ee1-4698-8e78-afc33a8f512e"
      },
      "source": [
        "resp = 'severe_toxic'\n",
        "training_labels = train[resp]\n",
        "train_features = train_tfidf_features\n",
        "seed = 1234\n",
        "splits = 5\n",
        "folds = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n",
        "  \n",
        "over = SMOTE(sampling_strategy=0.1,random_state=seed)\n",
        "X_re, y_re = over.fit_resample(train_features, training_labels)\n",
        "class_pred = np.zeros(X_re.shape[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2XcWubNhtuj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "85c233be-8f26-4bfe-eed1-5df4108c3229"
      },
      "source": [
        "##### Investigating class imbalance + improving recall #####\n",
        "resp = 'severe_toxic'\n",
        "training_labels = train[resp]\n",
        "train_features = train_tfidf_features\n",
        "seed = 1234\n",
        "splits = 5\n",
        "folds = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n",
        "\n",
        "\n",
        "#under = RandomUnderSampler(sampling_strategy=0.5)\n",
        "\n",
        "## 1) Oversampling\n",
        "over_ratios = [0.05,0.1,0.15,0.2,0.3,0.4,0.5]\n",
        "\n",
        "for ratio in over_ratios:\n",
        "  # Define new re-sampled data\n",
        "  over = SMOTE(sampling_strategy=ratio,random_state=seed)\n",
        "  X_re, y_re = over.fit_resample(train_features, training_labels)\n",
        "  class_pred = np.zeros(X_re.shape[0])\n",
        "  print(\"Class distribution with ratio {}: \".format(str(ratio)),sorted(Counter(y_re).items()))\n",
        "  # Use 5-fold cross-validation to evaluate performance at given over-sampling ratio.\n",
        "  auc,precision,recall,thresholds = [],[],[],[]\n",
        "  for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_re, y_re)):\n",
        "    # Train NB-SVM with oversample ratio\n",
        "    model = NbSvmClassifier(C=4, tol=1e-4, dual=False, n_jobs=-1,multi_class='auto').fit(X_re[trn_idx], y_re[trn_idx])\n",
        "    class_pred[val_idx] = model.predict_proba(X_re[val_idx])[:,1]\n",
        "    auc.append(roc_auc_score(y_re[val_idx], class_pred[val_idx],average='weighted'))\n",
        "    prec, recal, thresh = precision_recall_curve(y_re[val_idx], class_pred[val_idx])\n",
        "    precision.append(prec)\n",
        "    recall.append(recal)\n",
        "    thresholds.append(thresh)\n",
        "  # Print out mean AUC score\n",
        "  print(\"SMOTE ratio: \",str(ratio),' | mean AUC: ',str(round(np.mean(auc),4)))\n",
        "  # Plot precision-recall curve\n",
        "  plt.figure()\n",
        "  plt.plot(recall[0], precision[0], 'ro', linewidth=2,label='Fold 1 Preds')\n",
        "  plt.plot(recall[1], precision[1], 'bo', linewidth=2,label='Fold 2 Preds')\n",
        "  plt.plot(recall[2], precision[2], 'go', linewidth=2,label='Fold 3 Preds')\n",
        "  plt.plot(recall[3], precision[3], 'yo', linewidth=2,label='Fold 4 Preds')\n",
        "  plt.plot(recall[4], precision[4], 'mo', linewidth=2,label='Fold 5 Preds')\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.title('Ratio: '+str(ratio)+' | Average Precision: '+str(average_precision_score(y_re,class_pred,average='weighted')))\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Class distribution with ratio 0.05:  [(0, 157976), (1, 7898)]\n",
            "SMOTE ratio:  0.05  | mean AUC:  0.9965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGJPkLBAYY0yS+/8m8nkSpDzzzgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Class distribution with ratio 0.1:  [(0, 157976), (1, 15797)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_zCGU9IqADX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit model using 5-fold CV, display PR curve\n",
        "resp = 'severe_toxic'\n",
        "train_features = train_tfidf_features\n",
        "\n",
        "training_labels = train[resp]\n",
        "class_pred = np.zeros(train_features.shape[0])\n",
        "auc,precision,recall,thresholds = [],[],[],[]\n",
        "\n",
        "# Make predictions for each fold in split, calculate evaluation metrics\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train_features, training_labels)):\n",
        "  # Train NB-SVM\n",
        "  model = NbSvmClassifier(C=4, tol=1e-4, dual=False, n_jobs=-1,multi_class='auto')\n",
        "  model.fit(train_features[trn_idx], training_labels[trn_idx])\n",
        "  class_pred[val_idx] = model.predict_proba(train_features[val_idx])[:,1]\n",
        "  auc.append(roc_auc_score(training_labels[val_idx], class_pred[val_idx],average='weighted'))\n",
        "  prec, recal, thresh = precision_recall_curve(training_labels[val_idx], class_pred[val_idx])\n",
        "  precision.append(prec)\n",
        "  recall.append(recal)\n",
        "  thresholds.append(thresh)\n",
        "\n",
        "# Print out mean AUC score\n",
        "print(\"fit: \",resp,' | mean AUC: ',str(round(np.mean(auc),4)))\n",
        "print(\"Thresholds: \"+str(thresholds[4]))\n",
        "print(\"Precision: \"+str(precision[4]))\n",
        "# Plot precision-recall curve\n",
        "plt.figure()\n",
        "plt.plot(recall[0], precision[0], 'ro', linewidth=2,label='Fold 1 Preds')\n",
        "plt.plot(recall[1], precision[1], 'bo', linewidth=2,label='Fold 2 Preds')\n",
        "plt.plot(recall[2], precision[2], 'go', linewidth=2,label='Fold 3 Preds')\n",
        "plt.plot(recall[3], precision[3], 'yo', linewidth=2,label='Fold 4 Preds')\n",
        "plt.plot(recall[4], precision[4], 'mo', linewidth=2,label='Fold 5 Preds')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Class: '+resp+' | Average Precision: '+str(average_precision_score(training_labels,class_pred,average='weighted')))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3tTu71X3gUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Fit NBSVM Model #####\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "train_features = train_tfidf_features\n",
        "\n",
        "#class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "class_names = ['severe_toxic','threat','identity_hate']\n",
        "seed = 1234\n",
        "splits = 5\n",
        "folds = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n",
        "\n",
        "for i, j in enumerate(class_names):\n",
        "    training_labels = train[j]\n",
        "    class_pred = np.zeros(len(train))\n",
        "    auc,precision,recall,thresholds = [],[],[],[]\n",
        "\n",
        "    # Make predictions for each fold in split, calculate evaluation metrics\n",
        "    for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train_features, training_labels)):\n",
        "      # Train NB-SVM\n",
        "      model = NbSvmClassifier(C=4, tol=1e-4, dual=False, n_jobs=-1,multi_class='auto')\n",
        "      model.fit(train_features[trn_idx], training_labels[trn_idx])\n",
        "      class_pred[val_idx] = model.predict_proba(train_features[val_idx])[:,1]\n",
        "      auc.append(roc_auc_score(training_labels[val_idx], class_pred[val_idx],average='weighted'))\n",
        "      prec, recal, thresh = precision_recall_curve(training_labels[val_idx], class_pred[val_idx])\n",
        "      precision.append(prec)\n",
        "      recall.append(recal)\n",
        "      thresholds.append(thresh)\n",
        "\n",
        "    # Print out mean AUC score\n",
        "    print(\"fit: \",j,' | mean AUC: ',str(round(np.mean(auc),4)))\n",
        "    print(\"Thresholds: \"+str(thresholds[4]))\n",
        "    print(\"Precision: \"+str(precision[4]))\n",
        "    # Plot precision-recall curve\n",
        "    plt.figure()\n",
        "    plt.plot(recall[0], precision[0], 'ro', linewidth=2,label='Fold 1 Preds')\n",
        "    plt.plot(recall[1], precision[1], 'bo', linewidth=2,label='Fold 2 Preds')\n",
        "    plt.plot(recall[2], precision[2], 'go', linewidth=2,label='Fold 3 Preds')\n",
        "    plt.plot(recall[3], precision[3], 'yo', linewidth=2,label='Fold 4 Preds')\n",
        "    plt.plot(recall[4], precision[4], 'mo', linewidth=2,label='Fold 5 Preds')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Class: '+j+' | Average Precision: '+str(average_precision_score(training_labels,class_pred,average='weighted')))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgseRNtSa4O8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Bayesian Hyperparameter Tuning for Severe Toxic Class #####\n",
        "\n",
        "#warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "train_features = train_tfidf_features\n",
        "\n",
        "class_names_2 = ['severe_toxic', 'threat', 'identity_hate']\n",
        "seed = 1234\n",
        "splits = 5\n",
        "folds = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n",
        "\n",
        "j = 'threat'\n",
        "training_labels = train[j]\n",
        "class_pred = np.zeros(train_features.shape[0])\n",
        "auc,precision,recall,thresholds = [],[],[],[]\n",
        "\n",
        "### Define functions for Bayesian Hyperparameter Optimization (SMBO using TPE)\n",
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK, space_eval\n",
        "from sklearn.metrics import r2_score, roc_auc_score, accuracy_score, f1_score, confusion_matrix, classification_report, roc_curve, make_scorer\n",
        "\n",
        "# 1) Define objective \n",
        "\n",
        "def objective(params):\n",
        "    time1 = time.time()\n",
        "    params = {\n",
        "        'C': params['C'],\n",
        "        'tol': params['tol'],\n",
        "    }\n",
        "\n",
        "    print(\"\\n############## New Run ################\")\n",
        "    print(f\"params = {params}\")\n",
        "    seed = 1234\n",
        "    splits = 5\n",
        "    folds = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n",
        "    score_mean = 0\n",
        "    class_pred = np.zeros(train_features.shape[0])\n",
        "\n",
        "    for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train_features, training_labels)):\n",
        "      clf = NbSvmClassifier(C=params['C'], tol=params['tol'], dual=False,n_jobs=-1,multi_class='auto')\n",
        "      clf.fit(train_features[trn_idx], training_labels[trn_idx])\n",
        "      class_pred[val_idx] = clf.predict_proba(train_features[val_idx])[:,1]\n",
        "      score = average_precision_score(training_labels[val_idx],class_pred[val_idx],average='weighted')\n",
        "      score_mean += score\n",
        "    time2 = time.time() - time1\n",
        "    print(f\"Total Time Run: {round(time2 / 60,2)}\")\n",
        "    #gc.collect()\n",
        "    print(f'Average Precision Score: {score_mean/splits}')\n",
        "    return -(score_mean / splits)\n",
        "\n",
        "\n",
        "# 2) Define search space\n",
        "\n",
        "space = {\n",
        "    'C': hp.lognormal('C', 0,1),\n",
        "    'tol': hp.choice('tol',[1e-7,1e-6,1e-5,1e-4,1e-3,1e-2])\n",
        "}    \n",
        "\n",
        "# 3) Specify Optimization algorithm\n",
        "tpe_algo = tpe.suggest\n",
        "\n",
        "# 4) Instantiate Trials object to track results\n",
        "tpe_trials = Trials()\n",
        "\n",
        "# Set hyperopt parameters\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe_algo,\n",
        "            trials = tpe_trials,\n",
        "            max_evals=1000)\n",
        "# Print best parameters\n",
        "best_params = space_eval(space, best)\n",
        "print(\"BEST PARAMS: \", best_params)\n",
        "\n",
        "# Make predictions for each fold in split, calculate evaluation metrics\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train_features, training_labels)):\n",
        "  # Train NB-SVM\n",
        "  model = NbSvmClassifier(C=best_params['C'], tol=best_params['tol'], dual=False, n_jobs=-1,multi_class='auto')\n",
        "  model.fit(train_features[trn_idx], training_labels[trn_idx])\n",
        "  class_pred[val_idx] = model.predict_proba(train_features[val_idx])[:,1]\n",
        "  auc.append(roc_auc_score(training_labels[val_idx], class_pred[val_idx],average='weighted'))\n",
        "  prec, recal, thresh = precision_recall_curve(training_labels[val_idx], class_pred[val_idx])\n",
        "  precision.append(prec)\n",
        "  recall.append(recal)\n",
        "  thresholds.append(thresh)\n",
        "\n",
        "# Print out mean AUC score\n",
        "print(\"fit: \",j,' | mean AUC: ',str(round(np.mean(auc),4)))\n",
        "# Plot precision-recall curve\n",
        "plt.figure()\n",
        "plt.plot(recall[0], precision[0], 'ro', linewidth=2,label='Fold 1 Preds')\n",
        "plt.plot(recall[1], precision[1], 'bo', linewidth=2,label='Fold 2 Preds')\n",
        "plt.plot(recall[2], precision[2], 'go', linewidth=2,label='Fold 3 Preds')\n",
        "plt.plot(recall[3], precision[3], 'yo', linewidth=2,label='Fold 4 Preds')\n",
        "plt.plot(recall[4], precision[4], 'mo', linewidth=2,label='Fold 5 Preds')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Class: '+j+' | Average Precision: '+str(average_precision_score(training_labels,class_pred,average='weighted')))\n",
        "plt.legend()\n",
        "plt.show()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}