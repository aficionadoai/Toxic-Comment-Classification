## Toxic Comment Classification Kaggle
This repository contains code for my submission to the Toxic Comment Classification Challenge on Kaggle.
https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview

## Background of Competition
In this competition, competitors are challenged to build a multi-label text classifier that’s capable of detecting different types of toxicity. Toxicity is defined according to six categories: toxic, severe_toxic, obscene, threat, insult, identity_hate. The training and test data are derived from a dataset of comments from Wikipedia’s talk page edits.

## Solution

