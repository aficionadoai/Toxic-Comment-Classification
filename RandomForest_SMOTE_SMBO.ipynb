{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForest_SMOTE_SMBO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markerenberg/Toxic-Comment-Classification/blob/master/RandomForest_SMOTE_SMBO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6AvEhk7_upV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if GPU is enabled\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHXV-Uu90Ldo",
        "colab_type": "code",
        "outputId": "9ff5f2a1-f037-4462-e220-29ac50266f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "##\n",
        "## =======================================================\n",
        "## Mark Erenberg \n",
        "## Toxic Comment Classification Challenge\n",
        "## =======================================================\n",
        "##\n",
        "\n",
        "# Objective: Create a model which predicts a probability of each type of toxicity for each comment.\n",
        "\n",
        "# import dependencies and files\n",
        "\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "from scipy.sparse import hstack\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import tempfile\n",
        "import warnings\n",
        "import ast\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "\n",
        "import nltk\n",
        "#nltk.download()\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "import gensim\n",
        "import gensim.models.keyedvectors as word2vec\n",
        "from gensim.models.fasttext import FastText\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "import gensim.downloader as api\n",
        "\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "spacy_nlp = en_core_web_sm.load()\n",
        "spacy_nlp = spacy.load('en_core_web_sm')\n",
        "from spacy.lemmatizer import Lemmatizer\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "from sklearn import utils\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, average_precision_score, classification_report\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Bidirectional, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model, Sequential\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "from imblearn.over_sampling import SMOTE, SVMSMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "################### Data Loading ###################\n",
        "#os.chdir('C:\\\\Users\\\\marke\\\\Downloads\\\\Toxic Classification')\n",
        "train = pd.read_csv('train.csv').fillna('')\n",
        "test = pd.read_csv('test.csv').fillna('')\n",
        "\n",
        "train_text = train[['id','comment_text']].drop_duplicates()\n",
        "df = pd.concat([train_text,test],axis=0,ignore_index=True)\n",
        "\n",
        "################### Load Spell Check ###################\n",
        "# Load word2vec model pre-trained on Google News corpus (3 billion running words) \n",
        "\"\"\"\n",
        "t0 = time.time()\n",
        "google = api.load('word2vec-google-news-300')\n",
        "\n",
        "words = google.index2word\n",
        "\n",
        "w_rank = {}\n",
        "for i,word in enumerate(words):\n",
        "    w_rank[word] = i\n",
        "WORDS = w_rank\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "def P(word): \n",
        "    \"Probability of `word`.\"\n",
        "    # use inverse of rank as proxy\n",
        "    # returns 0 if the word isn't in the dictionary\n",
        "    return - WORDS.get(word, 0)\n",
        "\n",
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "\n",
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word): \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
        "\n",
        "print(\"Time taken to load SpellChecker: {}m\".format(round((time.time()-t0)/60,2)))\n",
        "\"\"\"\n",
        "################### Data Cleaning ####################\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "cv = CountVectorizer(min_df=0., max_df=1.)\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "# Simple way to get the number of occurence of a regex\n",
        "def count_regexp_occ(regexp=\"\", text=None):\n",
        "    return len(re.findall(regexp, text))\n",
        "\n",
        "# Determine if file words exist:\n",
        "#print(len(df[df['comment_text'].str.contains('jpg')]))\n",
        "#print(len(df[df['comment_text'].str.contains('jpeg')]))\n",
        "#print(len(df[df['comment_text'].str.contains('http')]))\n",
        "#print(len(df[df['comment_text'].str.contains('pdf')]))\n",
        "#print(len(df[df['comment_text'].str.contains('html')]))\n",
        "\n",
        "# Remove non-alphabetic characters and split tokens by spaces/newlines\n",
        "def clean_document(doc,use_stop=True):\n",
        "    # 1) Convert string to lower\n",
        "    #doc = bytes(doc.lower(), encoding=\"utf-8\")\n",
        "    doc = doc.lower()\n",
        "    # 2) Replace contracion patterns\n",
        "    cont_patterns = [\n",
        "    (r'(W|w)on\\'t', r'will not'),\n",
        "    (r'(C|c)an\\'t', r'can not'),\n",
        "    (r'(I|i)\\'m', r'i am'),\n",
        "    (r'(A|a)in\\'t', r'is not'),\n",
        "    (r'(\\w+)\\'ll', r'\\g<1> will'),\n",
        "    (r'(\\w+)n\\'t', r'\\g<1> not'),\n",
        "    (r'(\\w+)\\'ve', r'\\g<1> have'),\n",
        "    (r'(\\w+)\\'s', r'\\g<1> is'),\n",
        "    (r'(\\w+)\\'re', r'\\g<1> are'),\n",
        "    (r'(\\w+)\\'d', r'\\g<1> would'),\n",
        "    ]\n",
        "    patterns = [(re.compile(regex), repl) for (regex, repl) in cont_patterns]\n",
        "    for (pattern, repl) in patterns:\n",
        "        doc = re.sub(pattern, repl, doc)\n",
        "    # 3) Remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]+', r' ', doc)\n",
        "    # 4) Remove extra whitespaces\n",
        "    doc = re.sub(r\"\\s+\",r\" \",doc)\n",
        "    # 5) Remove leading/trailing whitespaces\n",
        "    doc = doc.strip()\n",
        "    # tokenize document\n",
        "    tokens = wpt.tokenize(doc)\n",
        "    if use_stop:\n",
        "      # filter stopwords out of document\n",
        "      filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    else:\n",
        "      filtered_tokens = tokens\n",
        "    # re-create document from filtered tokens\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    #doc = ' '.join(tokens)\n",
        "    return doc\n",
        "\n",
        "# Old-school lemmatization\n",
        "def lemmatize_comment(comment):\n",
        "        doc = spacy_nlp(comment)\n",
        "        return [token.lemma_ for token in doc if token.lemma_ != '-PRON-']         \n",
        "\n",
        "# Spell-check, then lemmatize\n",
        "def spell_and_lemmatize(doc):\n",
        "    # 1) Replace contraction patterns\n",
        "    cont_patterns = [\n",
        "    (r'(W|w)on\\'t', r'will not'),\n",
        "    (r'(C|c)an\\'t', r'can not'),\n",
        "    (r'(I|i)\\'m', r'i am'),\n",
        "    (r'(A|a)in\\'t', r'is not'),\n",
        "    (r'(\\w+)\\'ll', r'\\g<1> will'),\n",
        "    (r'(\\w+)n\\'t', r'\\g<1> not'),\n",
        "    (r'(\\w+)\\'ve', r'\\g<1> have'),\n",
        "    (r'(\\w+)\\'s', r'\\g<1> is'),\n",
        "    (r'(\\w+)\\'re', r'\\g<1> are'),\n",
        "    (r'(\\w+)\\'d', r'\\g<1> would'),\n",
        "    ]\n",
        "    patterns = [(re.compile(regex), repl) for (regex, repl) in cont_patterns]\n",
        "    for (pattern, repl) in patterns:\n",
        "        doc = re.sub(pattern, repl, doc)\n",
        "    # 2) Remove special characters, replace newlines with spaces, remove extra spaces\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]+', ' ', doc)\n",
        "    doc = re.sub(r'[\\n\\r\\t\\r\\n]',r' ',doc,re.I|re.U)\n",
        "    doc = re.sub(r\"\\s+\",r\" \",doc)\n",
        "    # 3) Remove leading and trailing whitespaces\n",
        "    doc = doc.strip()\n",
        "    # 4) Filter only verbs, nouns, adjectives, and adverbs. Remove stopwords.\n",
        "    filtered = [token.text for token in spacy_nlp(doc) if token.pos_ in ['VERB','NOUN','ADJ','ADV','PROPN'] and token.text.lower() not in stop_words]\n",
        "    # 5) Spell-check words that are not proper nouns\n",
        "    corrected = [correction(token.text) if token.pos_ != 'PROPN' else token.text for token in spacy_nlp(\" \".join(filtered))]\n",
        "    # 6) Apply lemmatization to spell-checked words\n",
        "    lemmas = [token.lemma_ if token.pos_ != 'PROPN' else token.text for token in spacy_nlp(\" \".join(corrected))]\n",
        "    # 7) Remove pronouns, convert to lowercase\n",
        "    final_lemmas = [token.text.lower() for token in spacy_nlp(\" \".join(lemmas)) if token.lemma_ != '-PRON-']\n",
        "    return final_lemmas\n",
        "\n",
        "## Clean and lemmatize comments\n",
        "#df['clean_comments'] = [clean_document(x) for x in df['comment_text']]\n",
        "#df['clean_comments_list'] = df['clean_comments'].apply(lambda x: x.split())\n",
        "#df['clean_lemmed'] = [lemmatize_comment(x) for x in df['clean_comments']]\n",
        "#df['clean_lemmed_str'] = df['clean_lemmed'].apply(lambda x: \" \".join(x))\n",
        "#train['clean_comments'] = [clean_document(x) for x in train['comment_text']]\n",
        "#train['clean_comments_list'] = train['clean_comments'].apply(lambda x: x.split())\n",
        "#train['clean_lemmed'] = [spell_and_lemmatize(x) for x in train['comment_text']]\n",
        "#train['clean_lemmed_str'] = train['clean_lemmed'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "## Write to csv for download\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#train['clean_comments'].to_csv('train_clean_comments.csv',sep=',',index=False)\n",
        "#train['clean_lemmed_str'].to_csv('train_clean_lemmed.csv',sep=',',index=False)\n",
        "\n",
        "## Read from csv\n",
        "train_clean_comments = pd.read_csv('train_clean_comments.csv',header=None)\n",
        "train_clean_lemmed = pd.read_csv('train_clean_lemmed.csv',header=None)\n",
        "\n",
        "## Transform cleaned/lemmed strings\n",
        "train['clean_comments'] = train_clean_comments[0].apply(lambda x: str(x))\n",
        "train['clean_comments_list'] = train['clean_comments'].apply(lambda x: x.split())\n",
        "#train['clean_lemmed'] = train_clean_lemmed[0].apply(lambda x: str(x))\n",
        "#train['clean_lemmed_list'] = train['clean_lemmed'].apply(lambda x: x.split())\n",
        "train['clean_lemmed'] = train_clean_lemmed[0].apply(lambda x: ast.literal_eval(x))\n",
        "train['clean_lemmed_str'] = train['clean_lemmed'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HsGQpdB9hFMJ",
        "colab": {}
      },
      "source": [
        "################### Feature Engineering ###################\n",
        "\n",
        "# TF-IDF Vectorizer\n",
        "train_text = train['clean_lemmed_str']\n",
        "\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    #min_df = 3,\n",
        "    #max_df = 0.9,\n",
        "    sublinear_tf=True,\n",
        "    #smooth_idf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=20000)\n",
        "word_vectorizer.fit(train_text)\n",
        "train_word_features = word_vectorizer.transform(train_text)\n",
        "\n",
        "char_vectorizer = TfidfVectorizer(\n",
        "    #min_df = 3,\n",
        "    #max_df = 0.9,\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='char',\n",
        "    stop_words='english',\n",
        "    ngram_range=(2, 6),\n",
        "    max_features=20000)\n",
        "char_vectorizer.fit(train_text)\n",
        "train_char_features = char_vectorizer.transform(train_text)\n",
        "\n",
        "tfidf_features = hstack([train_char_features, train_word_features]).tocsr()\n",
        "#train_tfidf_features = train_word_features.tocsr()\n",
        "\n",
        "# Create features about type of text and category of text\n",
        "def add_features(df):\n",
        "    # Get length in words and characters\n",
        "    df[\"word_count\"] = df[\"comment_text\"].apply(lambda x: len(x.split()))\n",
        "    df[\"word_len_avg\"] = df[\"comment_text\"].apply(lambda x: np.mean([len(x) for x in x.split()]))\n",
        "    df[\"word_len_std\"] = df[\"comment_text\"].apply(lambda x: np.std([len(x) for x in x.split()]))\n",
        "    df[\"char_count\"] = df[\"comment_text\"].apply(lambda x: len(x))\n",
        "    # Create count variables to see if any are useful\n",
        "    df[\"upper_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[A-Z]\", x)) /df['char_count']*100\n",
        "    df[\"number_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[0-9]\", x)) / df[\"char_count\"] *100\n",
        "    df[\"excl_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\!\", x)) / df[\"char_count\"] *100\n",
        "    df[\"quest_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\?\", x)) / df[\"char_count\"] *100\n",
        "    df[\"equals_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\=\", x)) / df[\"char_count\"] *100\n",
        "    df[\"punct_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[\\.\\!\\?\\=\\+\\#\\*\\|\\~\\-\\,]\", x)) / df[\"char_count\"] *100\n",
        "    df[\"you_ratio\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\W[Yy][oO][uU]\\W\", x)) / df[\"word_count\"] *100\n",
        "    df[\"nb_fuck\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[Ff][uU][cC][Kk]\", x))\n",
        "    df[\"nb_shit\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[Ss][Hh][Ii][Tt]\", x))\n",
        "    df[\"nb_kill\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[kK][iI][lL][lL]\", x))\n",
        "    df[\"nb_die\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\s[dD][iI][eE]\\s\", x))\n",
        "    df[\"nb_suck\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[Ss]\\S{2}[Kk]\", x))\n",
        "    df[\"nb_dick\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[dD][iI][cC][kK]\", x))\n",
        "    df[\"nb_penis\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[pP][eE][nN][iI][sS]\", x))\n",
        "    df[\"nb_pussy\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[pP][uU][sS][sS][yY]\", x))\n",
        "    df[\"nb_cock\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[cC][oO][cC][kK]\", x))\n",
        "    df[\"8==D\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"8=+D\", x))\n",
        "    df[\"nb_piss\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[pP][iI][sS][sS]\", x))\n",
        "    df[\"nb_gay\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[gG][aA][yY]\", x))\n",
        "    df[\"nb_bitch\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[bB][iI][tT][cC][hH]\", x))\n",
        "    df[\"nb_retard\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[rR][eE][tT][aA][rR][dD]\", x))\n",
        "    df[\"nb_cunt\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[cC][uU][nN][tT]\", x))\n",
        "    df[\"nb_idiot\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[iI][dD][iI][oO][tT]\", x))\n",
        "    df[\"nb_stupid\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[sS][tT][uU][pP][iI][dD]\", x))\n",
        "    df[\"nb_dumb\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[dD][uU][mM][bB]\", x))\n",
        "    df[\"nb_shut_up\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[sS][hH][uU][tT]\\s[uU][pP]\", x))\n",
        "    df[\"nb_mother\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\s[mM][oO][tT][hH][eE][rR](\\W|\\s|$)\", x))\n",
        "    df[\"nb_ng\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\s[nN][iI][gG][gG][eE][rR](\\W|\\s|$)\", x))\n",
        "    df[\"nb_fat\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\s[Ff][aA][tT](\\W|\\s|$)\", x))\n",
        "    df[\"nb_ass\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"((\\W|\\s|$)[aA][sS][sS]\\w)|(\\w[aA][sS][sS](\\W|\\s|$))\", x))\n",
        "    df[\"nb_fg\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[fF][aA][gG][gG][oO][tT]\", x))\n",
        "    df[\"nb_fg_2\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"\\s[fF][aA][gG](\\W|\\s|$)\", x))\n",
        "    df[\"nb_cancer\"] = df[\"comment_text\"].apply(lambda x: count_regexp_occ(r\"[cC][aA][nN][cC][eE][rR]\", x))\n",
        "    return\n",
        "\n",
        "def pos_tagging(df):\n",
        "    df[\"comment_raw\"] = df[\"comment_text\"].apply(lambda x: re.sub(r'[\\n\\r\\t\\r\\n]',r' ',x,re.I|re.U))\n",
        "    df[\"POS\"] = df[\"comment_raw\"].apply(lambda x: [token.pos_ for token in spacy_nlp(x)])\n",
        "    return\n",
        "    \n",
        "def pos_features(df):\n",
        "    # Get number of proper nouns\n",
        "    df[\"PROPN\"] = df[\"POS\"].apply(lambda x: len([pos for pos in x if pos == 'PROPN']))\n",
        "    df[\"ADJ\"] = df[\"POS\"].apply(lambda x: len([pos for pos in x if pos == 'ADJ']))\n",
        "    df[\"INTJ\"] = df[\"POS\"].apply(lambda x: len([pos for pos in x if pos == 'INTJ']))\n",
        "    df[\"SYM\"] = df[\"POS\"].apply(lambda x: len([pos for pos in x if pos == 'SYM']))\n",
        "    return\n",
        "\n",
        "## Create features\n",
        "add_features(train)\n",
        "pos_tagging(train)\n",
        "pos_features(train)\n",
        "\n",
        "## Look for duplicate comments\n",
        "\"\"\"\n",
        "Defining duplicate as: any time a comment appears more than twice.\n",
        "\"\"\"\n",
        "comment_counts = train['clean_comments'].value_counts().to_dict()\n",
        "train['is_duplicate'] = train['clean_comments'].apply(lambda x: int(comment_counts[x]>1))\n",
        "#print(train.loc[train['is_duplicate']==1,class_names].sum(axis=0))\n",
        "\n",
        "## Look for spam comments\n",
        "\"\"\"\n",
        "Defining spam as: any comment that has the same sentence repeated twice.\n",
        "\"\"\"\n",
        "train['comment_list'] = train['comment_text'].apply(lambda x: (clean_document(x,use_stop=True)).split())\n",
        "\n",
        "def count_duplicates(seq): \n",
        "    '''\n",
        "    takes as argument a sequence and returns the number of duplicate elements\n",
        "    ex: count_duplicates([\"hello world.\",\"hello world.\",\"hello world.\"]) -> 2\n",
        "    ex: count_duplicates([\"hello world\",\"fuck disneyland\",\"hello world\"]) -> 1\n",
        "    '''\n",
        "    return len(seq) - len(set(seq))\n",
        "\n",
        "def count_non_duplicates(seq):\n",
        "  '''\n",
        "  takes as argument a list of words, and returns the percentage of words that are duplicates\n",
        "  '''\n",
        "  if len(set(seq)) == 0: return 0\n",
        "  count_dict = Counter(seq)\n",
        "  dup_words = [word for (word,count) in count_dict.items() if count >= 2]\n",
        "  return len(dup_words)/len(set(seq))\n",
        "  \n",
        "train['is_spam'] = train['comment_list'].apply(lambda x: int(count_non_duplicates(x)>=0.5))\n",
        "#print(train.loc[train['is_spam']==1,class_names].sum(axis=0))\n",
        "\n",
        "meta_features = train.drop(['id','comment_text','clean_comments','clean_comments_list','clean_lemmed','clean_lemmed_str','clean_lemmed_list','comment_raw','POS','sentence_list','repeated_sentences','comment_list']+class_names,axis=1,inplace=False,errors='ignore')\n",
        "train_features = hstack([sparse.csr_matrix(meta_features.values), tfidf_features]).tocsr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiYfLT5uX6RG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set parameters\n",
        "lgb_params = {\n",
        "    \"objective\": \"binary\",\n",
        "    'metric': 'binary_error',\n",
        "    'is_unbalance': True,\n",
        "    \"boosting_type\": \"gbdt\",\n",
        "    \"verbosity\": -1,\n",
        "    \"num_threads\": -1,\n",
        "    \"bagging_fraction\": 0.8,\n",
        "    \"feature_fraction\": 0.8,\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"reg_lambda\":0,\n",
        "    \"num_leaves\": 31,\n",
        "    \"verbose\": -1\n",
        "}\n",
        "\n",
        "xgb_params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    'eval_metric': 'map',\n",
        "    \"booster\": \"gbtree\",\n",
        "    \"verbosity\": 0,\n",
        "    \"subsample\": 0.7,\n",
        "    \"colsample_bytree\": 0.7,\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"lambda\":1,\n",
        "    \"num_leaves\": 31\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2XcWubNhtuj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "7ebd08a7-d3be-45f3-be9e-b5b9474bda8f"
      },
      "source": [
        "##### Investigating class imbalance + improving recall #####\n",
        "resp = 'severe_toxic'\n",
        "training_labels = train[resp]\n",
        "seed = 1234\n",
        "splits = 5\n",
        "folds = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n",
        "use_lgb=False\n",
        "use_smote = False\n",
        "\n",
        "## Over_sampling and under_sampling\n",
        "#over_ratios = [0.05,0.1,0.2]\n",
        "under_ratios = [0.025,0.05,0.1,0.15]\n",
        "\n",
        "#for ratio in under_ratios:\n",
        "# Define new re-sampled data\n",
        "class_pred = np.zeros(train_features.shape[0])\n",
        "# Use 5-fold cross-validation to evaluate performance at given over-sampling ratio.\n",
        "auc,precision,recall,thresholds,f_scores,best_t = [],[],[],[],[],[]\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train_features, training_labels)):\n",
        "  if use_smote:\n",
        "    # Define pipeline to oversample, undersample, and then cross-validate\n",
        "    #over = SMOTE(sampling_strategy=0.025,k_neighbors=10)\n",
        "    under = TomekLinks(sampling_strategy='majority')\n",
        "    #under = RandomUnderSampler(sampling_strategy=ratio)\n",
        "    #steps = [('over', over), ('under', under), ('model', model)]\n",
        "    #pipeline = Pipeline(steps=steps)\n",
        "    # evaluate pipeline\n",
        "    X_re, y_re = under.fit_resample(train_features[trn_idx],training_labels[trn_idx])\n",
        "    #X_re, y_re = under.fit_resample(X_re,y_re)   \n",
        "    X_train = X_re\n",
        "    y_train = y_re\n",
        "  else:\n",
        "    X_train =  train_features[trn_idx]\n",
        "    y_train = training_labels[trn_idx]\n",
        "  if use_lgb:\n",
        "    trn_lgbset = lgb.Dataset(X_train, free_raw_data=False)\n",
        "    trn_lgbset.set_label(y_train)\n",
        "    lgb_rounds = 500\n",
        "    #weight_ratio = np.sum(training_labels[trn_idx] == 0) / np.sum(training_labels[trn_idx] == 1)\n",
        "    #lgb_params['scale_pos_weight'] = weight_ratio\n",
        "    model = lgb.train(params=lgb_params,\n",
        "                      train_set=trn_lgbset, \n",
        "                      num_boost_round=lgb_rounds,\n",
        "                      valid_sets=[lgb.Dataset(train_features[val_idx], free_raw_data=False)],\n",
        "                      early_stopping_rounds=50,\n",
        "                      verbose_eval=0)\n",
        "    class_pred[val_idx] = model.predict(train_features[val_idx], num_iteration=model.best_iteration)\n",
        "  else:\n",
        "    dtrain = xgb.DMatrix(X_train,label=y_train) \n",
        "    dval =  xgb.DMatrix(train_features[val_idx],label=training_labels[val_idx]) \n",
        "    watchlist = [(dtrain,'train'), (dval, 'valid')]\n",
        "    xgb_rounds=200\n",
        "    #weight_ratio = np.sum(X_re == 0) / np.sum(y_re == 1)\n",
        "    #print(\"Weight ratio: \",weight_ratio)\n",
        "    #xgb_params['scale_pos_weight'] = weight_ratio \n",
        "    model = xgb.train(params=xgb_params,\n",
        "                      dtrain=dtrain,\n",
        "                      num_boost_round=xgb_rounds,\n",
        "                      evals=watchlist,\n",
        "                      early_stopping_rounds=50,\n",
        "                      verbose_eval=False)\n",
        "    class_pred[val_idx] = model.predict(xgb.DMatrix(train_features[val_idx]), ntree_limit = model.best_ntree_limit)\n",
        "  auc.append(roc_auc_score(training_labels[val_idx], class_pred[val_idx],average='weighted'))\n",
        "  prec, recal, thresh = precision_recall_curve(training_labels[val_idx], class_pred[val_idx])\n",
        "  precision.append(prec)\n",
        "  recall.append(recal)\n",
        "  thresholds.append(thresh)\n",
        "  # Find optimal threshold\n",
        "  fscore = (2 * prec * recal) / (prec + recal)\n",
        "  # locate the index of the largest f score\n",
        "  ix = np.argmax(fscore)\n",
        "  print('Fold ', n_fold, ':','Best Threshold=%f, F-Score=%.3f' % (thresh[ix], fscore[ix]))\n",
        "  best_t.append(thresh[ix])\n",
        "  f_scores.append(fscore[ix])\n",
        "\n",
        "# Print out mean AUC score\n",
        "print(\"Class: \",resp,' | mean AUC: ',str(round(np.mean(auc),4)))\n",
        "print(\"Class: \",resp,' | mean F-Score: ',str(round(np.mean(f_scores),4)))\n",
        "print(\"Avg best threshold: \",str(round(np.mean(best_t),4)))\n",
        "# Plot precision-recall curve\n",
        "plt.figure()\n",
        "plt.plot(recall[0], precision[0], 'ro', linewidth=2,label='Fold 1 Preds')\n",
        "plt.plot(recall[1], precision[1], 'bo', linewidth=2,label='Fold 2 Preds')\n",
        "plt.plot(recall[2], precision[2], 'go', linewidth=2,label='Fold 3 Preds')\n",
        "plt.plot(recall[3], precision[3], 'yo', linewidth=2,label='Fold 4 Preds')\n",
        "plt.plot(recall[4], precision[4], 'mo', linewidth=2,label='Fold 5 Preds')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Class: '+resp+' | Average Precision: '+str(average_precision_score(training_labels,class_pred,average='weighted')))\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold=0.251440, F-Score=0.472\n",
            "Best Threshold=0.200090, F-Score=0.503\n",
            "Best Threshold=0.207257, F-Score=0.525\n",
            "Best Threshold=0.190769, F-Score=0.505\n",
            "Best Threshold=0.186424, F-Score=0.508\n",
            "Class:  severe_toxic  | mean AUC:  0.9868\n",
            "Avg best threshold:  0.2072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKqWAjMWGwxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Extract comments that were mislabelled #####\n",
        "dtrain = xgb.DMatrix(X_train,label=y_train) \n",
        "    dval =  xgb.DMatrix(train_features[val_idx],label=training_labels[val_idx]) \n",
        "    watchlist = [(dtrain,'train'), (dval, 'valid')]\n",
        "    xgb_rounds=200\n",
        "    #weight_ratio = np.sum(X_re == 0) / np.sum(y_re == 1)\n",
        "    #print(\"Weight ratio: \",weight_ratio)\n",
        "    #xgb_params['scale_pos_weight'] = weight_ratio \n",
        "    model = xgb.train(params=xgb_params,\n",
        "                      dtrain=dtrain,\n",
        "                      num_boost_round=xgb_rounds,\n",
        "                      evals=watchlist,\n",
        "                      early_stopping_rounds=50,\n",
        "                      verbose_eval=False)\n",
        "    class_pred[val_idx] = model.predict(xgb.DMatrix(train_features[val_idx]), ntree_limit = model.best_ntree_limit)\n",
        "  auc.append(roc_auc_score(training_labels[val_idx], class_pred[val_idx],average='weighted'))\n",
        "  prec, recal, thresh = precision_recall_curve(training_labels[val_idx], class_pred[val_idx])\n",
        "  precision.append(prec)\n",
        "  recall.append(recal)\n",
        "  thresholds.append(thresh)\n",
        "  # Find optimal threshold\n",
        "  fscore = (2 * prec * recal) / (prec + recal)\n",
        "  # locate the index of the largest f score\n",
        "  ix = np.argmax(fscore)\n",
        "  print('Fold ', n_fold, ':','Best Threshold=%f, F-Score=%.3f' % (thresh[ix], fscore[ix]))\n",
        "  best_t.append(thresh[ix])\n",
        "  f_scores.append(fscore[ix])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgseRNtSa4O8",
        "colab_type": "code",
        "outputId": "24eab5e9-ad0f-4798-9b34-633c480f737a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "##### Bayesian Hyperparameter Tuning for LightGBM/XGBoost #####\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Define variables for CV\n",
        "#class_names = ['severe_toxic', 'threat', 'identity_hate']\n",
        "seed = 1234\n",
        "splits = 5\n",
        "folds = StratifiedKFold(n_splits=splits, shuffle=True, random_state=seed)\n",
        "class_pred = np.zeros(train_features.shape[0])\n",
        "auc,precision,recall,thresholds = [],[],[],[]\n",
        "use_lgb = False\n",
        "\n",
        "# Define response class\n",
        "resp = 'severe_toxic'\n",
        "training_labels = train[resp]\n",
        "\n",
        "### Define functions for Bayesian Hyperparameter Optimization (SMBO using TPE)\n",
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK, space_eval\n",
        "from sklearn.metrics import r2_score, roc_auc_score, accuracy_score, f1_score, confusion_matrix, classification_report, roc_curve, make_scorer\n",
        "\n",
        "# 1) Define objective \n",
        "\n",
        "def objective(params):\n",
        "    time1 = time.time()\n",
        "    if use_lgb:\n",
        "      params = {\n",
        "          'learning_rate': params['learning_rate'],\n",
        "          'bagging_fraction': params['bagging_fraction'],\n",
        "          'feature_fraction': params['feature_fraction']}\n",
        "    else:\n",
        "        params = {\n",
        "          'learning_rate': params['learning_rate'],\n",
        "          'subsample': params['bagging_fraction'],\n",
        "          'colsample_bytree': params['feature_fraction']}\n",
        "    print(\"\\n############## New Run ################\")\n",
        "    print(f\"params = {params}\")\n",
        "    score_mean = 0\n",
        "    class_pred = np.zeros(train_features.shape[0])\n",
        "\n",
        "    for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train_features, training_labels)):\n",
        "      if use_lgb:\n",
        "        trn_lgbset = lgb.Dataset(train_features[trn_idx], free_raw_data=False)\n",
        "        trn_lgbset.set_label(training_labels[trn_idx])\n",
        "        clf = lgb.train(params=params,\n",
        "                        train_set=trn_lgbset, \n",
        "                        num_boost_round=lgb_rounds,\n",
        "                        valid_sets=[lgb.Dataset(train_features[val_idx], free_raw_data=False)],\n",
        "                        early_stopping_rounds=50,\n",
        "                        verbose_eval=0)\n",
        "        class_pred[val_idx] = clf.predict(train_features[val_idx], num_iteration=clf.best_iteration)\n",
        "      else:\n",
        "        dtrain = xgb.DMatrix(train_features[trn_idx],label=training_labels[trn_idx]) \n",
        "        dval =  xgb.DMatrix(train_features[val_idx],label=training_labels[val_idx]) \n",
        "        watchlist = [(dtrain,'train'), (dval, 'valid')]\n",
        "        xgb_rounds=100 \n",
        "        clf = xgb.train(params=params,\n",
        "                          dtrain=dtrain,\n",
        "                          num_boost_round=xgb_rounds,\n",
        "                          evals=watchlist,\n",
        "                          early_stopping_rounds=50,\n",
        "                          verbose_eval=False)\n",
        "        class_pred[val_idx] = clf.predict(xgb.DMatrix(train_features[val_idx]), ntree_limit = clf.best_ntree_limit)\n",
        "\n",
        "      score = average_precision_score(training_labels[val_idx],class_pred[val_idx],average='weighted')\n",
        "      score_mean += score\n",
        "    time2 = time.time() - time1\n",
        "    print(f\"Total Time Run: {round(time2 / 60,2)}\")\n",
        "    #gc.collect()\n",
        "    print(f'Average Precision Score: {score_mean/splits}')\n",
        "    return (score_mean / splits)\n",
        "\n",
        "\n",
        "# 2) Define search space\n",
        "\n",
        "space = {    \n",
        "    # reg_lambda: L2 regularization term. L2 encourages smaller weights, this\n",
        "    # approach can be more useful in tree-models where zeroing \n",
        "    # features might not make much sense.\n",
        "    #'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
        "    \n",
        "    # Learning rate: Rate at which trees learn from error of previous models\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "    \n",
        "    # feature_fraction: Controls the subsampling of features used. Smaller fractions reduce overfitting.\n",
        "    'feature_fraction': hp.uniform('feature_fraction', 0.5, 1),\n",
        "    \n",
        "    # bagging_fraction and bagging_freq: Enables bagging (subsampling) of the training data.  Smaller fractions and frequencies reduce overfitting.\n",
        "    'bagging_fraction': hp.uniform('bagging_fraction', 0.5, 1)\n",
        "    \n",
        "}\n",
        "\n",
        "# 3) Specify Optimization algorithm\n",
        "tpe_algo = tpe.suggest\n",
        "\n",
        "# 4) Instantiate Trials object to track results\n",
        "tpe_trials = Trials()\n",
        "\n",
        "# Set hyperopt parameters\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe_algo,\n",
        "            trials = tpe_trials,\n",
        "            \n",
        "\n",
        "            max_evals=100)\n",
        "# Print best parameters\n",
        "best_params = space_eval(space, best)\n",
        "print(\"BEST PARAMS: \", best_params)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "############## New Run ################\n",
            "params = {'learning_rate': 0.09771042464864453, 'subsample': 0.500264062121279, 'colsample_bytree': 0.7204083200781088}\n",
            "  0%|          | 0/100 [00:22<?, ?it/s, best loss: ?]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6553bfee0b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             max_evals=100)\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;31m# Print best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspace_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         )\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    405\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    406\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-6553bfee0b86>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mclass_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mdval\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsc_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_init_from_csr\u001b[0;34m(self, csr)\u001b[0m\n\u001b[1;32m    436\u001b[0m         _check_call(_LIB.XGDMatrixCreateFromCSREx(c_array(ctypes.c_size_t, csr.indptr),\n\u001b[1;32m    437\u001b[0m                                                   \u001b[0mc_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_uint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                                                   \u001b[0mc_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m                                                   \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_size_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                                                   \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_size_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mc_array\u001b[0;34m(ctype, values)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mctype\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mctype\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkZEXIL57n7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set LGBM parameters\n",
        "# Set parameters\n",
        "lgb_params = {\n",
        "    \"objective\": \"binary\",\n",
        "    'metric': 'map',\n",
        "    #'is_unbalance': True,\n",
        "    \"boosting_type\": \"gbdt\",\n",
        "    \"verbosity\": -1,\n",
        "    \"num_threads\": -1,\n",
        "    'learning_rate': params['learning_rate'],\n",
        "    'bagging_fraction': params['bagging_fraction'],\n",
        "    'feature_fraction': params['feature_fraction'],\n",
        "    \"reg_lambda\":0,\n",
        "    \"num_leaves\": 31,\n",
        "    \"verbose\": -1\n",
        "}\n",
        "\n",
        "xgb_params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    'eval_metric': 'map',\n",
        "    \"booster\": \"gbtree\",\n",
        "    \"verbosity\": 0,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"lambda\":1,\n",
        "    \"num_leaves\": 31\n",
        "}\n",
        "\n",
        "# Make predictions for each fold in split, calculate evaluation metrics\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train_features, training_labels)):\n",
        "  # Train Hyperoptimized LightGBM\n",
        "  trn_lgbset = lgb.Dataset(train_features[trn_idx], free_raw_data=False)\n",
        "  trn_lgbset.set_label(training_labels[trn_idx])\n",
        "  model = lgb.train(params=params,\n",
        "                    train_set=trn_lgbset, \n",
        "                    num_boost_round=lgb_rounds,\n",
        "                    valid_sets=[lgb.Dataset(train_features[val_idx], free_raw_data=False)],\n",
        "                    early_stopping_rounds=50,\n",
        "                    verbose_eval=0)\n",
        "  class_pred[val_idx] = model.predict(train_features[val_idx], num_iteration=model.best_iteration)\n",
        "  auc.append(roc_auc_score(training_labels[val_idx], class_pred[val_idx],average='weighted'))\n",
        "  prec, recal, thresh = precision_recall_curve(training_labels[val_idx], class_pred[val_idx])\n",
        "  precision.append(prec)\n",
        "  recall.append(recal)\n",
        "  thresholds.append(thresh)\n",
        "\n",
        "# Print out mean AUC score\n",
        "print(\"class: \",resp,' | mean AUC: ',str(round(np.mean(auc),4)))\n",
        "# Plot precision-recall curve\n",
        "plt.figure()\n",
        "plt.plot(recall[0], precision[0], 'ro', linewidth=2,label='Fold 1 Preds')\n",
        "plt.plot(recall[1], precision[1], 'bo', linewidth=2,label='Fold 2 Preds')\n",
        "plt.plot(recall[2], precision[2], 'go', linewidth=2,label='Fold 3 Preds')\n",
        "plt.plot(recall[3], precision[3], 'yo', linewidth=2,label='Fold 4 Preds')\n",
        "plt.plot(recall[4], precision[4], 'mo', linewidth=2,label='Fold 5 Preds')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Class: '+resp+' | Average Precision: '+str(average_precision_score(training_labels,class_pred,average='weighted')))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}